{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55f5594b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded SNV data from AVPC/ACC9/9-post.snv.txt with shape (3862, 4)\n",
      "Loaded CNA data from AVPC/ACC9/9-post.cna.txt with shape (181, 6)\n",
      "Purity: 0.21\n",
      "Constructed df with shape (3862, 11)\n",
      "Warning: No match in CNA for row 733 but found major_cn=2.0 and minor_cn=2.0. Expected defaults 1 and 1.\n",
      "Loaded SNV data from AVPC/ACC9/9-pre.snv.txt with shape (5576, 4)\n",
      "Loaded CNA data from AVPC/ACC9/9-pre.cna.txt with shape (277, 6)\n",
      "Purity: 0.31\n",
      "Constructed df with shape (5576, 11)\n",
      "Warning: No match in CNA for row 2772 but found major_cn=2.0 and minor_cn=1.0. Expected defaults 1 and 1.\n",
      "Warning: No match in CNA for row 3764 but found major_cn=2.0 and minor_cn=1.0. Expected defaults 1 and 1.\n",
      "Warning: No match in CNA for row 5445 but found major_cn=2.0 and minor_cn=2.0. Expected defaults 1 and 1.\n",
      "Warning: No match in CNA for row 3991 but found major_cn=2.0 and minor_cn=1.0. Expected defaults 1 and 1.\n",
      "Warning: No match in CNA for row 3429 but found major_cn=2.0 and minor_cn=1.0. Expected defaults 1 and 1.\n",
      "Process done. Created outputs in E:/Dropbox/GitHub/Multi_Region_CliPP/processed_data/acc9post.\n"
     ]
    }
   ],
   "source": [
    "from clipp2.core1 import *\n",
    "from clipp2.preprocess import *\n",
    "df1 = process_files('AVPC/ACC9/9-post.snv.txt', 'AVPC/ACC9/9-post.cna.txt','AVPC/ACC9/9-post.purity.txt')\n",
    "df2 = process_files('AVPC/ACC9/9-pre.snv.txt', 'AVPC/ACC9/9-pre.cna.txt','AVPC/ACC9/9-pre.purity.txt')\n",
    "[df1, df2] = insert_distinct_rows_multi([df1, df2])\n",
    "export_snv_cna_and_purity(\n",
    "        df1,\n",
    "        dir=\"AVPC/ACC9pre/\",\n",
    "        snv_path=\"9post.snv.txt\",\n",
    "        cna_path=\"9post.cna.txt\",\n",
    "        purity_path=\"9post.purity.txt\"\n",
    "    )\n",
    "export_snv_cna_and_purity(\n",
    "        df2,\n",
    "        dir=\"AVPC/ACC9pre/\",\n",
    "        snv_path=\"9pre.snv.txt\",\n",
    "        cna_path=\"9pre.cna.txt\",\n",
    "        purity_path=\"9pre.purity.txt\"\n",
    "    )\n",
    "snv_file      = \"AVPC/ACC9pre/9post.snv.txt\"\n",
    "cn_file       = \"AVPC/ACC9pre/9post.cna.txt\"\n",
    "purity_file   = \"AVPC/ACC9pre/9post.purity.txt\"\n",
    "sample_id     = \"--sample_id\"   # not heavily used in logic\n",
    "output_prefix = \"E:/Dropbox/GitHub/Multi_Region_CliPP/processed_data/acc9post\"\n",
    "\n",
    "# Call function with drop_data=True (to replicate R code's dropping logic)\n",
    "process_data(\n",
    "    snv_file, cn_file, purity_file, sample_id, output_prefix, \n",
    "    drop_data=False\n",
    ")\n",
    "snv_file      = \"AVPC/ACC9pre/9pre.snv.txt\"\n",
    "cn_file       = \"AVPC/ACC9pre/9pre.cna.txt\"\n",
    "purity_file   = \"AVPC/ACC9pre/9pre.purity.txt\"\n",
    "sample_id     = \"--sample_id\"   # not heavily used in logic\n",
    "output_prefix = \"E:/Dropbox/GitHub/Multi_Region_CliPP/processed_data/acc9pre\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0deefcf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process done. Created outputs in E:/Dropbox/GitHub/Multi_Region_CliPP/processed_data/acc9pre.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Dropbox\\GitHub\\Multi_Region_CliPP\\clipp2\\preprocess.py:763: RuntimeWarning: divide by zero encountered in divide\n",
      "  phi_arr = 2.0 / ( (minor_count / (minor_read/total_read)) - total_count + 2.0 )\n"
     ]
    }
   ],
   "source": [
    "# Call function with drop_data=True (to replicate R code's dropping logic)\n",
    "process_data(\n",
    "    snv_file, cn_file, purity_file, sample_id, output_prefix, \n",
    "    drop_data=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57d8adfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded region 'acc9post': r.shape=(5793,), coef.shape=(5793, 6), purity=0.21\n",
      "Loaded region 'acc9pre': r.shape=(5793,), coef.shape=(5793, 6), purity=0.31\n",
      "\n",
      "=== Summary of grouped data before dropping rows ===\n",
      "Found M=2 regions. r shape= (5793, 2), n= (5793, 2)\n",
      "minor= (5793, 2), total= (5793, 2)\n",
      "coef_list length= 2 (each is (No_mutation,6))\n",
      "wcut= [-0.18  1.8 ]\n",
      "\n",
      "Dropped 0 rows that were all-zero in r/n/minor/total/coef.\n",
      "\n",
      "=== Summary of grouped data after dropping rows ===\n",
      "r shape= (5793, 2), n= (5793, 2)\n",
      "minor= (5793, 2), total= (5793, 2)\n",
      "coef_list length= 2, each => shape (5793, 6)\n"
     ]
    }
   ],
   "source": [
    "root_dir = \"E:/Dropbox/GitHub/Multi_Region_CliPP/processed_data\"\n",
    "(r, n, minor, total, purity, coef_list, wcut, drop) = group_all_regions_for_ADMM(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f22c4087",
   "metadata": {},
   "outputs": [],
   "source": [
    "wcut = [-1.8, 1.8]\n",
    "alpha=0.8\n",
    "gamma=3.7\n",
    "rho=1.02\n",
    "precision= 0.01\n",
    "Run_limit=1e4\n",
    "control_large=5\n",
    "Lambda=0.1\n",
    "post_th=0.05\n",
    "least_diff=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "450c4b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_2D_and_no_zeros(arr):\n",
    "    \"\"\"\n",
    "    - If arr is 1D, reshape to (No_mutation, 1).\n",
    "    - If arr is 2D, keep shape.\n",
    "    - Then replace any zeros with 1.\n",
    "    \"\"\"\n",
    "    if arr.ndim == 1:\n",
    "        arr = arr.reshape(-1, 1)\n",
    "    elif arr.ndim != 2:\n",
    "        raise ValueError(f\"Expected 1D or 2D array, got shape {arr.shape}\")\n",
    "    # Replace zeros with 1\n",
    "    # This is vectorized, no Python loops:\n",
    "    arr = np.where(arr == 0, 1, arr)\n",
    "    return arr\n",
    "\n",
    "r     = ensure_2D_and_no_zeros(r)\n",
    "n     = ensure_2D_and_no_zeros(n)\n",
    "minor = ensure_2D_and_no_zeros(minor)\n",
    "total = ensure_2D_and_no_zeros(total)\n",
    "\n",
    "No_mutation, M = r.shape\n",
    "\n",
    "# -------- 2) Broadcast purity => shape (No_mutation, M).  Fix ploidy=2.0. --------\n",
    "if np.isscalar(purity):\n",
    "    purity_arr = np.full((No_mutation, M), float(purity))\n",
    "else:\n",
    "    purity = np.asarray(purity, dtype=float)\n",
    "    if purity.ndim == 1 and purity.shape[0] == M:\n",
    "        purity_arr = np.broadcast_to(purity.reshape(1,M), (No_mutation, M))\n",
    "    else:\n",
    "        raise ValueError(f\"purity must be scalar or shape (M,). Got shape {purity.shape}.\")\n",
    "ploidy_arr = np.full((No_mutation, M), 2.0)\n",
    "\n",
    "# -------- 3) Compute w_new, using single-sample style bounding logic --------\n",
    "# fraction = (r + eps)/(n + 2eps), then scale by copy/purity factor, clip in [expit(-cl), expit(cl)]\n",
    "fraction = (r ) / (n )\n",
    "phi_hat  = fraction * ( (ploidy_arr - purity_arr*ploidy_arr) + (purity_arr*total) ) / minor\n",
    "\n",
    "scale_parameter = max(1.0, np.max(phi_hat))\n",
    "phi_new = phi_hat / scale_parameter\n",
    "\n",
    "low_b = expit(-control_large)\n",
    "up_b  = expit(control_large)\n",
    "phi_new = np.clip(phi_new, low_b, up_b)  # shape (No_mutation, M)\n",
    "\n",
    "w_init = logit(phi_new)\n",
    "w_init = np.clip(w_init, -control_large, control_large)\n",
    "w_new  = w_init.copy()\n",
    "\n",
    "# -------- 4) Build the DELTA operator with NO Python for-loops --------\n",
    "# We want pairs (i<j).  We'll use triu_indices:\n",
    "i_idx, j_idx = np.triu_indices(No_mutation, k=1)     # shape=(No_pairs,)\n",
    "No_pairs = i_idx.size                                # # of i<j pairs\n",
    "\n",
    "# For each pair k, we have M rows in the final big matrix.\n",
    "# row indices => (k*M + m) for m in [0..M-1].\n",
    "# We'll build them in bulk.\n",
    "row_block = np.arange(No_pairs)[:,None]*M + np.arange(M)   # shape=(No_pairs, M)\n",
    "# We want 2 columns per row block => one for +1 at col i, one for -1 at col j,\n",
    "# so the total rows = 2 * (No_pairs * M).  But the row index is the same for i and j.\n",
    "# => We'll horizontally stack row_block with itself, then flatten.\n",
    "row_block_2 = np.hstack((row_block, row_block))            # shape=(No_pairs, 2*M)\n",
    "row_idx = row_block_2.ravel()                              # shape=(2*M*No_pairs,)\n",
    "\n",
    "# For column indices => i_idx[k], j_idx[k] => i_idx[k]*M + m\n",
    "col_block_i = i_idx[:,None]*M + np.arange(M)   # shape=(No_pairs, M)\n",
    "col_block_j = j_idx[:,None]*M + np.arange(M)   # shape=(No_pairs, M)\n",
    "col_block_2 = np.hstack((col_block_i, col_block_j))  # shape=(No_pairs, 2*M)\n",
    "col_idx = col_block_2.ravel()\n",
    "\n",
    "# For the data => +1 for i, -1 for j\n",
    "plus_ones  = np.ones_like(col_block_i)\n",
    "minus_ones = -np.ones_like(col_block_j)\n",
    "data_block = np.hstack((plus_ones, minus_ones))    # shape=(No_pairs, 2*M)\n",
    "vals = data_block.ravel()                          # shape=(2*M*No_pairs,)\n",
    "\n",
    "total_rows = No_pairs * M\n",
    "total_cols = No_mutation * M\n",
    "DELTA = sp.coo_matrix((vals, (row_idx, col_idx)),\n",
    "                        shape=(total_rows, total_cols)).tocsr()\n",
    "\n",
    "# -------- 5) Initialize eta, tau, residual, iteration k with NO loops --------\n",
    "# We can get the initial pairwise differences: w_new[i_idx,:] - w_new[j_idx,:]\n",
    "# shape => (No_pairs, M)\n",
    "eta_new = w_new[i_idx, :] - w_new[j_idx, :]\n",
    "\n",
    "# tau_new => just ones\n",
    "tau_new = np.ones_like(eta_new)\n",
    "\n",
    "# Large initial residual\n",
    "residual = 1e6\n",
    "k = 0\n",
    "\n",
    "c_all = np.stack(coef_list, axis=1)\n",
    "i_idx, j_idx = np.triu_indices(No_mutation, k=1)  \n",
    "No_pairs = i_idx.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44ccf27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration=1, alpha=0.816, residual=1.375\n",
      "Iteration=2, alpha=0.8323, residual=0.188225\n",
      "Iteration=3, alpha=0.849, residual=0.120146\n",
      "Iteration=4, alpha=0.8659, residual=0.0879087\n",
      "Iteration=5, alpha=0.8833, residual=0.0667848\n",
      "Iteration=6, alpha=0.9009, residual=0.0483592\n",
      "Iteration=7, alpha=0.9189, residual=0.0343762\n",
      "Iteration=8, alpha=0.9373, residual=0.0269698\n",
      "Iteration=9, alpha=0.9561, residual=0.0233618\n",
      "Iteration=10, alpha=0.9752, residual=0.0212269\n",
      "Iteration=11, alpha=0.9947, residual=0.0172917\n",
      "Iteration=12, alpha=1.015, residual=0.0165185\n",
      "Iteration=13, alpha=1.035, residual=0.0150461\n",
      "Iteration=14, alpha=1.056, residual=0.0143854\n",
      "Iteration=15, alpha=1.077, residual=0.0149511\n",
      "Iteration=16, alpha=1.098, residual=0.0114916\n",
      "Iteration=17, alpha=1.12, residual=0.0108306\n",
      "Iteration=18, alpha=1.143, residual=0.0106503\n",
      "Iteration=19, alpha=1.165, residual=0.0111917\n",
      "Iteration=20, alpha=1.189, residual=0.0108229\n",
      "Iteration=21, alpha=1.213, residual=0.0110554\n",
      "Iteration=22, alpha=1.237, residual=0.0105439\n",
      "Iteration=23, alpha=1.262, residual=0.0115726\n",
      "Iteration=24, alpha=1.287, residual=0.0224923\n",
      "Iteration=25, alpha=1.312, residual=0.0327423\n",
      "Iteration=26, alpha=1.339, residual=0.0378906\n",
      "Iteration=27, alpha=1.366, residual=0.0386953\n",
      "Iteration=28, alpha=1.393, residual=0.0400379\n"
     ]
    }
   ],
   "source": [
    "while k < Run_limit and residual > precision:\n",
    "    \n",
    "    k += 1    \n",
    "\n",
    "    w_old  = w_new.copy()\n",
    "    eta_old = eta_new.copy()\n",
    "    tau_old = tau_new.copy()\n",
    "\n",
    "    # =========================\n",
    "    # (A) IRLS expansions in bulk\n",
    "    # =========================\n",
    "\n",
    "    # 1) theta = (e^w * minor) / (2 + e^w * total)\n",
    "    expW   = np.exp(w_old)\n",
    "    denom_ = 2.0 + (expW*total)\n",
    "    # avoid zero denominators\n",
    "    denom_ = np.where(denom_==0, 1e-12, denom_)\n",
    "    theta  = (expW*minor)/denom_    # shape => (No_mutation, M)\n",
    "\n",
    "    # 2) Build partA, partB fully vectorized\n",
    "    #    shape => (No_mutation, M)\n",
    "    #    using c_all => shape(No_mutation, M, 6)\n",
    "    low_cut, up_cut = wcut\n",
    "    maskLow =  (w_old <= low_cut)\n",
    "    maskUp  =  (w_old >= up_cut)\n",
    "    maskMid = ~(maskLow | maskUp)\n",
    "\n",
    "    # partA_full = (branch on c_all[...,1], c_all[...,3], c_all[...,5]) \n",
    "    #              minus (r/n)\n",
    "    partA_full = (\n",
    "        (maskLow * c_all[...,1])\n",
    "        + (maskUp  * c_all[...,5])\n",
    "        + (maskMid * c_all[...,3])\n",
    "    ) - (r / n)\n",
    "\n",
    "    # partB_full similarly from c_all[...,0], c_all[...,2], c_all[...,4]\n",
    "    partB_full = (\n",
    "        (maskLow * c_all[...,0])\n",
    "        + (maskUp  * c_all[...,4])\n",
    "        + (maskMid * c_all[...,2])\n",
    "    )\n",
    "\n",
    "    # 3) A_array, B_array => multiply by sqrt(n) / sqrt(theta*(1-theta))\n",
    "    sqrt_n = np.sqrt(n)\n",
    "    # avoid zero => add small epsilon\n",
    "    denom2 = np.sqrt(theta*(1 - theta) + 1e-12)\n",
    "\n",
    "    A_array = (sqrt_n * partA_full) / denom2\n",
    "    B_array = (sqrt_n * partB_full) / denom2\n",
    "\n",
    "    # 4) Flatten them for the linear system\n",
    "    A_flat = A_array.ravel()    # shape => (No_mutation*M,)\n",
    "    B_flat = B_array.ravel()\n",
    "\n",
    "    # =========================\n",
    "    # (B) Form the linear system => (B^T B + alpha Delta^T Delta) w = ...\n",
    "    # =========================\n",
    "    # big_eta_tau => alpha*eta_old + tau_old\n",
    "    big_eta_tau = alpha*eta_old + tau_old\n",
    "    big_eta_tau_flat = big_eta_tau.ravel()\n",
    "\n",
    "    linear_1 = DELTA.transpose().dot(big_eta_tau_flat)\n",
    "    # linear_2 = B_flat * A_flat => elementwise, shape => (No_mutation*M,)\n",
    "    linear_2 = B_flat * A_flat\n",
    "    # final 'linear'\n",
    "    linear   = linear_1 - linear_2\n",
    "\n",
    "    # B^T B => diag of B_flat^2\n",
    "    B_sq = B_flat**2\n",
    "    Bmat = sp.diags(B_sq, 0, shape=(No_mutation*M, No_mutation*M))\n",
    "    H    = Bmat + alpha*(DELTA.transpose().dot(DELTA))\n",
    "\n",
    "    # Solve\n",
    "    w_new_flat = spsolve(H, linear)\n",
    "    w_new = w_new_flat.reshape(No_mutation, M)\n",
    "    # clip\n",
    "    np.clip(w_new, -control_large, control_large, out=w_new)\n",
    "\n",
    "    # =========================\n",
    "    # (C) SCAD threshold => eta_new, tau_new (already vectorized)\n",
    "    # =========================\n",
    "    eta_new, tau_new = scad_threshold_update(\n",
    "        w_new, tau_old, DELTA, alpha, Lambda, gamma\n",
    "    )\n",
    "\n",
    "    # scale alpha\n",
    "    alpha *= rho\n",
    "\n",
    "    # =========================\n",
    "    # (D) residual check in bulk (no for-loops)\n",
    "    # =========================\n",
    "    #  Residual = max_{pair} max_{m} | (w_new[i,:]-w_new[j,:]) - eta_new[k,:] |\n",
    "    #\n",
    "    # i_idx, j_idx => shape (No_pairs,)\n",
    "    # => compute w_new[i_idx,:] - w_new[j_idx,:], shape => (No_pairs, M)\n",
    "    # subtract eta_new => shape => (No_pairs, M)\n",
    "    diff_2D = (w_new[i_idx,:] - w_new[j_idx,:]) - eta_new\n",
    "    # compute max absolute difference\n",
    "    residual = np.max(np.abs(diff_2D))\n",
    "\n",
    "    print(f\"Iteration={k}, alpha={alpha:.4g}, residual={residual:.6g}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41da8bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ADMM finished.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 8., 1., ..., 9., 9., 9.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\nADMM finished.\\n\")\n",
    "\n",
    "diff = diff_mat(w_new)\n",
    "ids = np.triu_indices(diff.shape[1], 1)\n",
    "eta_new[np.where(np.abs(eta_new) <= post_th)] = 0\n",
    "diff[ids] = np.linalg.norm(eta_new, axis=1)\n",
    "class_label = -np.ones(No_mutation)\n",
    "class_label[0] = 0\n",
    "group_size = [1]\n",
    "labl = 1\n",
    "\n",
    "for i in range(1, No_mutation):\n",
    "    for j in range(i):\n",
    "        if diff[j, i] == 0:\n",
    "            class_label[i] = class_label[j]\n",
    "            group_size[int(class_label[j])] += 1\n",
    "            break\n",
    "    if class_label[i] == -1:\n",
    "        class_label[i] = labl\n",
    "        labl += 1\n",
    "        group_size.append(1)\n",
    "\n",
    "# quality control\n",
    "least_mut = np.ceil(0.05 * No_mutation)\n",
    "tmp_size = np.min(np.array(group_size)[np.array(group_size) > 0])\n",
    "tmp_grp = np.where(group_size == tmp_size)\n",
    "refine = False\n",
    "if tmp_size < least_mut:\n",
    "    refine = True\n",
    "\n",
    "while refine:\n",
    "    refine = False\n",
    "    tmp_col = np.where(class_label == tmp_grp[0][0])[0]\n",
    "    for i in range(len(tmp_col)):\n",
    "        if tmp_col[i] != 0 and tmp_col[i] != No_mutation - 1:\n",
    "            tmp_diff = np.abs(np.append(np.append(diff[0:tmp_col[i], tmp_col[i]].T.ravel(), 100),\n",
    "                                        diff[tmp_col[i], (tmp_col[i] + 1):No_mutation].ravel()))\n",
    "            tmp_diff[tmp_col] += 100\n",
    "            diff[0:tmp_col[i], tmp_col[i]] = tmp_diff[0:tmp_col[i]]\n",
    "            diff[tmp_col[i], (tmp_col[i] + 1):No_mutation] = tmp_diff[(tmp_col[i] + 1):No_mutation]\n",
    "        elif tmp_col[i] == 0:\n",
    "            tmp_diff = np.append(100, diff[0, 1:No_mutation])\n",
    "            tmp_diff[tmp_col] += 100\n",
    "            diff[0, 1:No_mutation] = tmp_diff[1:No_mutation]\n",
    "        else:\n",
    "            tmp_diff = np.append(diff[0:(No_mutation - 1), No_mutation - 1], 100)\n",
    "            tmp_diff[tmp_col] += 100\n",
    "            diff[0:(No_mutation - 1), No_mutation - 1] = tmp_diff[0:(No_mutation - 1)]\n",
    "        ind = tmp_diff.argmin()\n",
    "        group_size[class_label.astype(np.int64, copy=False)[tmp_col[i]]] -= 1\n",
    "        class_label[tmp_col[i]] = class_label[ind]\n",
    "        group_size[class_label.astype(np.int64, copy=False)[tmp_col[i]]] += 1\n",
    "    tmp_size = np.min(np.array(group_size)[np.array(group_size) > 0])\n",
    "    tmp_grp = np.where(group_size == tmp_size)\n",
    "    refine = False\n",
    "    if tmp_size < least_mut:\n",
    "        refine = True\n",
    "\n",
    "labels = np.unique(class_label)\n",
    "phi_out = np.zeros((len(labels), M))\n",
    "for i in range(len(labels)):\n",
    "    ind = np.where(class_label == labels[i])[0]\n",
    "    class_label[ind] = i\n",
    "    phi_out[i, :] = np.sum(phi_hat[ind, : ] * n[ind, : ], axis=0) / np.sum(n[ind, : ], axis=0)\n",
    "\n",
    "if len(labels) > 1:\n",
    "    sort_phi = sort_by_2norm(phi_out)\n",
    "    phi_diff = sort_phi[1:, :] - sort_phi[:-1, :]\n",
    "    min_ind, min_val = find_min_row_by_2norm(phi_diff)\n",
    "    while np.linalg.norm(min_val) < least_diff:\n",
    "        combine_ind = np.where(phi_out == sort_phi[min_ind, ])[0]\n",
    "        combine_to_ind = np.where(phi_out == sort_phi[min_ind + 1, ])[0]\n",
    "        class_label[class_label == combine_ind] = combine_to_ind\n",
    "        labels = np.unique(class_label)\n",
    "        phi_out = np.zeros((len(labels), M))\n",
    "        for i in range(len(labels)):\n",
    "            ind = np.where(class_label == labels[i])[0]\n",
    "            class_label[ind] = i\n",
    "            phi_out[i] = np.sum(phi_hat[ind, : ] * n[ind, : ], axis=0) / np.sum(n[ind, : ], axis=0)\n",
    "        if len(labels) == 1:\n",
    "            break\n",
    "        else:\n",
    "            sort_phi = sort_by_2norm(phi_out)\n",
    "            phi_diff = sort_phi[1:, :] - sort_phi[:-1, :]\n",
    "            min_ind, min_val = find_min_row_by_2norm(phi_diff)\n",
    "phi_res = np.zeros((No_mutation, M))\n",
    "for lab in range(np.shape(phi_out)[0]):\n",
    "    phi_res[class_label == lab, ] = phi_out[lab, ]\n",
    "class_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb939ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 8., 1., ..., 9., 9., 9.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb0b1bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
