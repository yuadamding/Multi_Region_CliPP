{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8094f901-3797-4547-90a7-9c49ddb330e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import itertools\n",
    "import random\n",
    "from scipy.stats import binom\n",
    "from scipy.stats import poisson\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41806dd7-c884-44ea-8d79-4be612a224b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Constants: hg38 reference\n",
    "\n",
    "hg38_configs = '''\n",
    "@SQ\tSN:chr1\tLN:248956422\n",
    "@SQ\tSN:chr2\tLN:242193529\n",
    "@SQ\tSN:chr3\tLN:198295559\n",
    "@SQ\tSN:chr4\tLN:190214555\n",
    "@SQ\tSN:chr5\tLN:181538259\n",
    "@SQ\tSN:chr6\tLN:170805979\n",
    "@SQ\tSN:chr7\tLN:159345973\n",
    "@SQ\tSN:chr8\tLN:145138636\n",
    "@SQ\tSN:chr9\tLN:138394717\n",
    "@SQ\tSN:chr10\tLN:133797422\n",
    "@SQ\tSN:chr11\tLN:135086622\n",
    "@SQ\tSN:chr12\tLN:133275309\n",
    "@SQ\tSN:chr13\tLN:114364328\n",
    "@SQ\tSN:chr14\tLN:107043718\n",
    "@SQ\tSN:chr15\tLN:101991189\n",
    "@SQ\tSN:chr16\tLN:90338345\n",
    "@SQ\tSN:chr17\tLN:83257441\n",
    "@SQ\tSN:chr18\tLN:80373285\n",
    "@SQ\tSN:chr19\tLN:58617616\n",
    "@SQ\tSN:chr20\tLN:64444167\n",
    "@SQ\tSN:chr21\tLN:46709983\n",
    "@SQ\tSN:chr22\tLN:50818468\n",
    "'''\n",
    "\n",
    "hg38_configs = [item.replace('SN:', '').replace('LN:', '').split('\\t')[1:] for item in [line for line in hg38_configs.split('\\n') if line != '' ]]\n",
    "hg38_configs = {key: int(value) for key, value in hg38_configs}\n",
    "\n",
    "hg38_names = list(hg38_configs.keys())\n",
    "hg38_lenghts = [hg38_configs[key] for key in hg38_names]\n",
    "hg38_start_end = [(1, hg38_configs[key] + 1) for key in hg38_names]\n",
    "hg38_lenghts_prob = [i / sum(hg38_lenghts) for i in hg38_lenghts]\n",
    "\n",
    "\n",
    "# Randomly generated copy number segements for hg38, assume there is only one segment per chrom\n",
    "hg38_totalCN = [2, 3, 2, 4, 3, 4, 2, 2, 2, 4, 3, 2, 2, 4, 1, 4, 4, 4, 4, 2, 1, 2]\n",
    "hg38_alCN = [(1, 1), (1, 2), (1, 1), (1, 3), (1, 2), (1, 3), (1, 1), (1, 1), (1, 1), (2, 2), (1, 2), (1, 1), (1, 1),\n",
    "             (1, 3), (1, 0), (1, 3), (2, 2), (3, 1), (1, 3), (1, 1), (1, 0), (1, 1)]\n",
    "\n",
    "chrom_size = 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a207eba7-f8b8-4926-92de-88dde2466e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## generation of a guided tree\n",
    "def gen_tree(n_nodes):\n",
    "    good_tree = False\n",
    "    while not good_tree:\n",
    "        tree = nx.generators.directed.gn_graph(np.random.randint(n_nodes, n_nodes + 1)).reverse()\n",
    "        if max([len(get_siblings(node, tree)) for node in tree.nodes()]) < 3: good_tree = True\n",
    "    return tree\n",
    "\n",
    "\n",
    "def nx_walk(node, tree):\n",
    "    \"\"\" iterate tree in pre-order depth-first search order \"\"\"\n",
    "    yield node\n",
    "    for child in sorted(tree.successors(node), key=lambda x: np.random.random()):\n",
    "        for n in nx_walk(child, tree):\n",
    "            yield n\n",
    "\n",
    "\n",
    "def get_siblings(node, tree):\n",
    "    try:\n",
    "        return tree.successors(tree.predecessors(node)[0])\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "\n",
    "def draw_graph(tree):\n",
    "    fig, axes = plt.subplots(1,1,dpi=72)\n",
    "    nx.draw(tree, pos=nx.spring_layout(tree), ax=axes, with_labels=True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def simulate_purity(n_samples, purity_range):\n",
    "    return [round(random.uniform(purity_range[0], purity_range[1]), 3) for _ in range(n_samples)]\n",
    "\n",
    "\n",
    "def simulate_missing_rate(n_samples, missing_rate_upper_limit):\n",
    "    return [round(random.uniform(0, missing_rate_upper_limit), 3) for _ in range(n_samples)]\n",
    "\n",
    "\n",
    "def gen_sample_from_tree_all(tree):\n",
    "    leaves = [node for node in tree.nodes() if len(list(tree.successors(node))) == 0]\n",
    "    leaves_to_include = leaves\n",
    "    non_zero_clusters = set(sum([list(nx_walk(x, tree.reverse())) for x in leaves_to_include], []))\n",
    "\n",
    "    clusters = [0.] * len(tree.nodes())\n",
    "\n",
    "    while min(np.diff(sorted(clusters))) < 0.02:\n",
    "        clusters = [0.] * len(tree.nodes())\n",
    "        for node in nx_walk(0, tree):\n",
    "            if node in non_zero_clusters:\n",
    "                if len(list(tree.predecessors(node))) == 0:  # clonal case\n",
    "                    clusters[node] = 1.\n",
    "                    continue\n",
    "\n",
    "                clusters[node] = (1 - random.random()) * (clusters[list(tree.predecessors(node))[0]] - sum([clusters[x] for x in get_siblings(node, tree)]))\n",
    "            else:\n",
    "                continue\n",
    "            # if len(tree.predecessors(node)) > 0:\n",
    "\n",
    "    return [round(x, 2) for x in clusters]\n",
    "\n",
    "\n",
    "def get_ccf_no_adj(mult, cn, alt, ref, PURITY, grid_size=101):\n",
    "\n",
    "    ccf_space = np.linspace(0, 1, grid_size)\n",
    "    ccf_dist = np.zeros(grid_size)\n",
    "\n",
    "    for mult_1_bin_val_idx, mult_1_bin_val in enumerate(ccf_space):\n",
    "        x = mult_1_bin_val * mult * PURITY / (\n",
    "                    float(mult_1_bin_val) * mult * PURITY + mult_1_bin_val * (cn - mult) * PURITY + (\n",
    "                        1 - mult_1_bin_val) * (cn) * PURITY + 2 * (1.0 - PURITY))\n",
    "        m1_draw = binom.pmf(alt, alt + ref, x)\n",
    "        ccf_dist[mult_1_bin_val_idx] = m1_draw\n",
    "\n",
    "    ccf_dist[np.isnan(ccf_dist)] = 0.\n",
    "    return ccf_dist / sum(ccf_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec67605e-db60-4841-af55-0cc908d84677",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def run_simulation(argv):\n",
    "    \n",
    "    n_clusters = int(argv['n_clusters'])\n",
    "    n_samples = int(argv['n_samples'])\n",
    "    read_depth = int(argv['read_depth'])\n",
    "    \n",
    "    n_mutations = int(argv['n_mutations'])\n",
    "    missing_rate = float(argv['missing_rate_upper_limit'])\n",
    "    purity = argv['purity']\n",
    "    if purity == 'uniform':\n",
    "        purity = simulate_purity(n_samples, purity_range=[0.4, 0.7])\n",
    "    missing_rate = simulate_missing_rate(n_samples, missing_rate_upper_limit=missing_rate)\n",
    "\n",
    "    output_root = argv['output_root']\n",
    "    replicate = int(argv['replicate'])\n",
    "    replicate += 1\n",
    "\n",
    "    if not os.path.exists(output_root):\n",
    "        os.mkdir(output_root)\n",
    "    \n",
    "    cn = 2.0 #ploidy of normal cells\n",
    "\n",
    "    good_sim = 0\n",
    "    while good_sim == 0:\n",
    "        tree = gen_tree(n_clusters)\n",
    "        clusters = [gen_sample_from_tree_all(tree) for x in range(max(n_samples, 2))]\n",
    "    \n",
    "        # Loops to check that clusters are not identical.\n",
    "        for c_idx, clust in enumerate(np.array(clusters).T):\n",
    "            if min(clust) < 0: continue \n",
    "            good_clust = 0\n",
    "            for s_c_idx, s_clust in enumerate(np.array(clusters).T):\n",
    "                if s_c_idx == c_idx: continue\n",
    "                if min(s_clust) < 0: continue\n",
    "    \n",
    "                if max(np.abs(clust - s_clust)) < 0.2: break\n",
    "            else:\n",
    "                good_clust = 1\n",
    "    \n",
    "            if good_clust == 0: break\n",
    "    \n",
    "        else:\n",
    "            good_sim = 1\n",
    "\n",
    "    ## Simulate proportions of SNVs counts in all clusters\n",
    "    \n",
    "    clust_props = [random.random() + 0.1 for x in sorted(clusters)[0]]\n",
    "    clust_props = [ x/sum(clust_props) for x in clust_props]\n",
    "\n",
    "    # for cluster in clusters:\n",
    "    #     print(cluster)\n",
    "\n",
    "    # draw_graph(tree)\n",
    "\n",
    "    output_handle = open(output_root + '/simulation_data_cluster_%s_region_%s_read_depth_%s_replica_%s.tsv' % (n_clusters, n_samples, read_depth, replicate), 'w')\n",
    "    _header = ['mutation', 'region', 'ref_counts', 'alt_counts', 'normal_cn', 'major_cn', 'minor_cn', 'tumour_purity', 'ccf', 'cluster']\n",
    "    _header = '\\t'.join(_header)\n",
    "    \n",
    "    output_handle.write(_header + '\\n')\n",
    "    \n",
    "    mutation_collection = dict()\n",
    "    \n",
    "    for mutation_index in range(n_mutations):\n",
    "        \n",
    "        config_index = np.argmax(np.random.multinomial(1, hg38_lenghts_prob))\n",
    "\n",
    "        chrom = hg38_names[config_index]\n",
    "        pos = random.choice(range(1, hg38_configs[chrom] + 1))\n",
    "        \n",
    "        ## same mutation should have the same cluster index, but different ccf\n",
    "        total_reads = poisson.rvs(read_depth, size=1).tolist()\n",
    "        total_reads = total_reads[0]\n",
    "        \n",
    "        total_CN = hg38_totalCN[config_index] ## assume clonal CN\n",
    "        al_1, al_2 = hg38_alCN[config_index]\n",
    "        al_CN = [al_1, al_2]\n",
    "\n",
    "        random.shuffle(al_CN)\n",
    "        new_alCN = al_CN[0]\n",
    "        if new_alCN == 0:\n",
    "            new_alCN = al_CN[1]\n",
    "\n",
    "        # Sample the multiplicity\n",
    "        # _temp = range(1, new_alCN + 1)\n",
    "        # _temp = [_item for _item in _temp]\n",
    "        # mult = random.choice(_temp)\n",
    "        mult = new_alCN\n",
    "        \n",
    "        cluster_index = np.argmax(np.random.multinomial(1, clust_props))\n",
    "        \n",
    "        for sample_index in range(n_samples):\n",
    "            if random.random() < missing_rate[sample_index]:\n",
    "                ccf = 0\n",
    "            else:\n",
    "                ccf = clusters[sample_index][cluster_index]\n",
    "\n",
    "            af = ccf * mult * purity[sample_index] / ( purity[sample_index] * total_CN + 2 * (1.0 - purity[sample_index]))\n",
    "            af = round(af, 4)\n",
    "\n",
    "            alt_reads = binom.rvs(total_reads, af, size=1).tolist()\n",
    "            alt_reads = alt_reads[0]\n",
    "            if af < 0.05: ## if af is too low, filter out this SNV from this region\n",
    "                af = 0\n",
    "                ccf = 0\n",
    "\n",
    "            if af == 0:\n",
    "                alt_reads = 0\n",
    "            \n",
    "            # multi_new = max([1, round(af / purity[sample_index] * (purity[sample_index] * total_CN + 2 * (1.0 - purity[sample_index])))])\n",
    "\n",
    "            major_cn = al_1 if al_1 > al_2 else al_2\n",
    "            minor_cn = al_1 if al_1 < al_2 else al_2\n",
    "            \n",
    "            _output = [chrom + ':' + str(pos), 'R' + str(sample_index + 1), str(total_reads - alt_reads), str(alt_reads),  str(2), str(major_cn), str(minor_cn), str(purity[sample_index]), str(ccf), str(cluster_index)]\n",
    "            _output = '\\t'.join(_output)\n",
    "\n",
    "            output_handle.write(_output + '\\n')\n",
    "            \n",
    "    output_handle.close()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    _output_root = 'multi_clipp_simulation_data_March4'\n",
    "\n",
    "\n",
    "    _argv = {\n",
    "        'n_clusters': 5,\n",
    "        'n_samples': 6,\n",
    "        'purity': 'uniform',\n",
    "        'read_depth': 100,\n",
    "        'n_mutations': 20, ## the union of SNVs in all regions\n",
    "        'missing_rate_upper_limit': 0.4, ## upper bound of missing rate \n",
    "        'output_root': _output_root,\n",
    "        'replicate': 1\n",
    "    }\n",
    "\n",
    "    run_simulation(_argv)\n",
    "\n",
    "    # for _replica in range(10): ## replicate\n",
    "    #     for _cluster in range(3, 9):\n",
    "    #         for _region in range(3, 11):\n",
    "    \n",
    "    #             for _read_depth in [100, 500, 1000]:\n",
    "    #             # if _cluster != 5 or _region != 6: \n",
    "    #             #     continue\n",
    "                    \n",
    "    #                 _argv = {\n",
    "    #                     'n_clusters': _cluster,\n",
    "    #                     'n_samples': _region,\n",
    "    #                     'purity': 'uniform',\n",
    "    #                     'read_depth': _read_depth,\n",
    "    #                     'n_mutations': 700, ## the union of SNVs in all regions\n",
    "    #                     'missing_rate_upper_limit': 0.4, ## \n",
    "    #                     'output_root': _output_root,\n",
    "    #                     'replicate': _replica\n",
    "    #                 }\n",
    "                \n",
    "    #                 run_simulation(_argv)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54c9b6c-a784-41ec-87c7-beb1bab1e60c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbf3480",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
